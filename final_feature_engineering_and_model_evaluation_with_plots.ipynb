{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f38f436a",
   "metadata": {},
   "source": [
    "# Enhanced Feature Engineering and Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d48df8d1",
   "metadata": {},
   "source": [
    "## Step 1: Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd25f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Load the enhanced data\n",
    "df = pd.read_csv('/mnt/data/enhanced_data.csv')\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86996ae0",
   "metadata": {},
   "source": [
    "## Step 2: Remove Irrelevant Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b631032",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Remove irrelevant columns\n",
    "irrelevant_columns = ['id', 'date_end', 'date_modif_prod', 'date_renewal']\n",
    "df.drop(columns=irrelevant_columns, inplace=True)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d24a6b",
   "metadata": {},
   "source": [
    "## Step 3: Expand the Dataset with New Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e53244f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Extract components from date columns (if not already extracted)\n",
    "df['year_activ'] = pd.to_datetime(df['date_activ']).dt.year\n",
    "df['month_activ'] = pd.to_datetime(df['date_activ']).dt.month\n",
    "df['day_activ'] = pd.to_datetime(df['date_activ']).dt.day\n",
    "df['day_of_week_activ'] = pd.to_datetime(df['date_activ']).dt.dayofweek\n",
    "df['quarter_activ'] = pd.to_datetime(df['date_activ']).dt.quarter\n",
    "df.drop(columns=['date_activ'], inplace=True)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e9376f8",
   "metadata": {},
   "source": [
    "## Step 4: Combine Columns to Create Better Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9cc157",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create a feature for total consumption by summing consumption columns\n",
    "df['total_consumption'] = df['cons_12m'] + df['cons_gas_12m'] + df['cons_last_month']\n",
    "\n",
    "# Create the new feature 'price_diff_dec_jan'\n",
    "df['price_off_peak_dec'] = df['var_6m_price_off_peak'] * 1.02  # Dummy calculation for December prices\n",
    "df['price_off_peak_jan'] = df['var_6m_price_off_peak'] * 0.98  # Dummy calculation for January prices\n",
    "df['price_diff_dec_jan'] = df['price_off_peak_dec'] - df['price_off_peak_jan']\n",
    "\n",
    "# Create interaction features\n",
    "df['price_consumption_interaction'] = df['total_consumption'] * df['price_diff_dec_jan']\n",
    "\n",
    "df[['price_off_peak_dec', 'price_off_peak_jan', 'price_diff_dec_jan', 'price_consumption_interaction']].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7be86bc",
   "metadata": {},
   "source": [
    "## Step 5: Prepare the Final Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef8a183",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Prepare the dataset\n",
    "features = df.drop(columns=['churn'])\n",
    "target = df['churn']\n",
    "\n",
    "# Identify categorical columns\n",
    "categorical_cols = features.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Define preprocessing pipeline for categorical features\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Combine preprocessing for numeric and categorical data\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', categorical_transformer, categorical_cols)\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.3, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8912faf1",
   "metadata": {},
   "source": [
    "## Step 6: Train and Evaluate the Model Without the New Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996af8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Exclude the new feature from training\n",
    "X_train_without_new = X_train.drop(columns=['price_diff_dec_jan'])\n",
    "X_test_without_new = X_test.drop(columns=['price_diff_dec_jan'])\n",
    "\n",
    "# Define the model\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Create and evaluate pipeline without the new feature\n",
    "pipeline_without_new = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', model)\n",
    "])\n",
    "\n",
    "# Train the model without the new feature\n",
    "pipeline_without_new.fit(X_train_without_new, y_train)\n",
    "predictions_without_new = pipeline_without_new.predict(X_test_without_new)\n",
    "accuracy_without_new = accuracy_score(y_test, predictions_without_new)\n",
    "roc_auc_without_new = roc_auc_score(y_test, predictions_without_new)\n",
    "\n",
    "accuracy_without_new, roc_auc_without_new\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df905ce",
   "metadata": {},
   "source": [
    "## Step 7: Train and Evaluate the Model With the New Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33191bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create and evaluate pipeline with the new feature\n",
    "pipeline_with_new = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', model)\n",
    "])\n",
    "\n",
    "# Train the model with the new feature\n",
    "pipeline_with_new.fit(X_train, y_train)\n",
    "predictions_with_new = pipeline_with_new.predict(X_test)\n",
    "accuracy_with_new = accuracy_score(y_test, predictions_with_new)\n",
    "roc_auc_with_new = roc_auc_score(y_test, predictions_with_new)\n",
    "\n",
    "accuracy_with_new, roc_auc_with_new\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef0c5343",
   "metadata": {},
   "source": [
    "## Step 8: Compare the Performance of Both Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58997c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(f'Accuracy without new feature: {accuracy_without_new}')\n",
    "print(f'ROC AUC without new feature: {roc_auc_without_new}')\n",
    "print(f'Accuracy with new feature: {accuracy_with_new}')\n",
    "print(f'ROC AUC with new feature: {roc_auc_with_new}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b08913a",
   "metadata": {},
   "source": [
    "## Step 9: Visualize the Performance Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b400fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plotting function to compare results\n",
    "def plot_comparison(title, y_label, values_without_new, values_with_new, labels):\n",
    "    x = range(len(values_without_new))\n",
    "    width = 0.4\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.bar(x, values_without_new, width, label='Without New Feature')\n",
    "    ax.bar([p + width for p in x], values_with_new, width, label='With New Feature')\n",
    "\n",
    "    ax.set_xlabel('Metrics')\n",
    "    ax.set_ylabel(y_label)\n",
    "    ax.set_title(title)\n",
    "    ax.set_xticks([p + width/2 for p in x])\n",
    "    ax.set_xticklabels(labels)\n",
    "    ax.legend()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Values for plotting\n",
    "metrics_labels = ['Accuracy', 'ROC AUC']\n",
    "values_without_new = [accuracy_without_new, roc_auc_without_new]\n",
    "values_with_new = [accuracy_with_new, roc_auc_with_new]\n",
    "\n",
    "# Plot the comparison\n",
    "plot_comparison('Model Performance Comparison', 'Score', values_without_new, values_with_new, metrics_labels)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
